# 👋 データエンジニア ポートフォリオ

## 🚀 About Me

データ基盤構築・ETL開発・BI分析環境の専門家として、大手企業のデータ活用を支援しています。  
複雑なデータパイプラインの設計から実装まで、エンドツーエンドのソリューションを提供します。

一貫して「データを活用して社内チームをサポートする」ことにやりがいを感じてきました。

営業事務時代、Excel VBAで在庫管理システムを構築し、通販商品全体で前年比120%の利益創出に貢献。H.I.S.では、Google Analyticsでデータ分析を行い、独自選定ツアーのメルマガで前週比1.3倍の反応率を達成し、上司から高評価をいただきました。この「データ分析→施策実行→結果確認→チームへの貢献」サイクルが、私の理想の働き方の原点です。

産後は子育てをしながら、ECサイトのマーケティング補助として、データ分析に触れ続けました。作業時間を75%削減する業務効率化を実現し、「もっとデータに深く関わりたい」と考え、データエンジニアに転身。

現在、データエンジニアとして1年10ヶ月、大手企業向けのデータ基盤構築・運用に従事。アパレル4ブランドのマーケティングタグ管理基盤の統合移行（2,724項目のテスト実施、タグ発火率99.8%達成）、BIデータマート構築（分析リードタイム96%削減）など、エンドツーエンドのデータエンジニアリング業務を提供。

次のキャリアでは、データエンジニアリングのスキルを活かしながら、分析・施策提案まで一貫して関わり、全体像が見える環境で社内チームに貢献できる仕事を実現したいと考えています。

### 💼 専門領域
- **データ基盤構築**: BigQuery, Treasure Data, GCPを活用した大規模データ基盤の設計・構築
- **ETL/ELT開発**: 複雑なデータ変換処理とパイプライン自動化
- **BI環境構築**: Tableau連携、多次元データマート設計
- **マーケティング分析**: GA4/GTM実装、タグ管理基盤移行、大規模統合移行プロジェクト

## 🛠️ Technical Skills

### 【データエンジニアリング】
- **SQL**（6年以上）：CTE、Window関数、複雑なJOIN、700行超の大規模クエリ開発
- **Python**（3年以上）：pandas、numpy、seaborn、selenium、requests、cryptography
- **JavaScript**：UDF開発、カスタムアルゴリズム実装、GTMカスタムHTML開発
- **クラウド**：GCP（BigQuery、Cloud Functions、Secret Manager）
- **データ基盤**：Treasure Data、Digdag
- **ETLパイプライン開発**：SFTP連携、API連携、データクレンジング

### 【マーケティング支援・データ分析】
- **マーケティングツール**：GTM、GA4、Tealium、Braze、LINE STAFF START、Silver Egg、Repro
- **GA4イベントトラッキング設計・実装**（11種類のEコマースイベント）
- **大規模タグ管理基盤の統合移行**（2,400項目、4ブランド並行、2,724項目の網羅的テスト実施）
- **メールマーケティング施策の企画・実行・効果測定**（前週比1.3倍の反応率達成）
- **Google Analytics、キーワードプランナーを活用したデータ分析・SEO対策**

### 【業務効率化】
- **Excel VBA、数式・関数を活用した業務自動化**（作業時間75%削減実績）
- **問題発見力・課題解決力**
- **AI開発支援ツール**（Claude、Cursor、GitHub Copilot）を活用した開発効率化

### データ基盤 & クラウド
![BigQuery](https://img.shields.io/badge/BigQuery-4285F4?style=for-the-badge&logo=google-cloud&logoColor=white)
![Treasure Data](https://img.shields.io/badge/Treasure_Data-FF6B6B?style=for-the-badge&logoColor=white)
![GCP](https://img.shields.io/badge/Google_Cloud-4285F4?style=for-the-badge&logo=google-cloud&logoColor=white)

### プログラミング言語
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![SQL](https://img.shields.io/badge/SQL-4479A1?style=for-the-badge&logo=postgresql&logoColor=white)
![JavaScript](https://img.shields.io/badge/JavaScript-F7DF1E?style=for-the-badge&logo=javascript&logoColor=black)

### ワークフロー & オーケストレーション
![Digdag](https://img.shields.io/badge/Digdag-2088FF?style=for-the-badge&logoColor=white)
![Cloud Functions](https://img.shields.io/badge/Cloud_Functions-4285F4?style=for-the-badge&logo=google-cloud&logoColor=white)

### 分析 & 可視化
![Tableau](https://img.shields.io/badge/Tableau-E97627?style=for-the-badge&logo=tableau&logoColor=white)
![GA4](https://img.shields.io/badge/Google_Analytics_4-E37400?style=for-the-badge&logo=google-analytics&logoColor=white)
![GTM](https://img.shields.io/badge/Google_Tag_Manager-246FDB?style=for-the-badge&logo=google-tag-manager&logoColor=white)

### AI開発支援ツール
![Claude](https://img.shields.io/badge/Claude-FF6B6B?style=for-the-badge&logoColor=white)
![Cursor](https://img.shields.io/badge/Cursor-4285F4?style=for-the-badge&logoColor=white)
![GitHub Copilot](https://img.shields.io/badge/GitHub_Copilot-181717?style=for-the-badge&logo=github&logoColor=white)

## 📊 実績データ

<table>
<tr>
<td align="center">
<h3>5件以上</h3>
<p>大規模プロジェクト</p>
</td>
<td align="center">
<h3>96%</h3>
<p>処理時間削減</p>
</td>
<td align="center">
<h3>99.9%</h3>
<p>システム稼働率</p>
</td>
<td align="center">
<h3>500万+</h3>
<p>日次処理レコード</p>
</td>
</tr>
</table>

## 🏆 主要プロジェクト

### 1. 👟 スポーツアパレル企業 SFCC API連携による大規模商品データ取込基盤構築
**役割**: データエンジニア（実装担当）  
**期間**: 2025年8月～9月  
**チーム規模**: 3名

- Salesforce Commerce Cloud SCAPI Products APIを用いた商品マスタデータ自動取込システムを開発
- **課題**: 
  - API制限（20件/リクエスト、レスポンスサイズ10MB上限）への対応
  - 累計10,000件超のメモリ効率的な処理が必要
- **技術実装**: 
  - OAuth 2.0認証（Client Credentials Flow）とトークン自動更新機能による長時間処理の安定化
  - バイナリサーチによる適応的期間分割アルゴリズムで、データ量に応じて日単位・時間単位を自動切り替え
  - Response Entity Too Largeエラー（10MB制限）発生時の自動期間再分割処理（最大5回リトライ）
  - 10万件単位のバッチ処理とメモリクリアによる効率的な大容量データ処理
  - 150項目以上のカラムマッピング辞書による自動変換（キャメルケース→スネークケース）
  - 5段階CTE処理による重複排除と完全なデータ正規化
- **成果**: 
  - Response Entity Too Largeエラーを自動処理し、安定した大容量データ取込を実現
  - バイナリサーチによる期間最適化でAPI呼び出し回数を最小化
  - 10万件バッチ処理でメモリ効率的な大量データ処理を実現
  - 150項目以上の複雑なカラムマッピングを正確に実装
- **技術**: Treasure Data, Digdag, Python (requests, pytd, pandas, json, datetime, time, os, base64), Salesforce Commerce Cloud SCAPI, OAuth 2.0, Presto SQL

### 2. ✈️ 大手不動産企業 空港事業部 GPS位置情報異常値検出・補正システムの開発
**役割**: データエンジニア（実装・顧客対応担当）  
**チーム規模**: 2名

- 国内旅行レンタルデバイスから収集されるGPS位置情報の異常値を自動検出・補正するシステムを開発
- **課題**: 時速1000km超の非現実的な移動、V字型異常パターン、座標の急激な変動により、正確な旅行経路分析が困難
- **技術実装**: 
  - JavaScript UDFによるHaversine公式を用いた球面距離計算アルゴリズム
  - 時速1000km超の非現実的な移動検出、V字型異常パターン検出、適応的傾向分析による座標補正
  - Window関数（LAG/LEAD/FIRST_VALUE/LAST_VALUE）を活用した時系列データ処理と日付間の連続性担保
  - 450行超のSQLクエリを10段階以上のCTE処理に分解し、ARRAY_AGG/UNNESTによる配列データ処理
- **成果**: 
  - GPS位置情報の異常値を自動検出・補正し、正確な旅行経路データの生成を実現
  - 450行超の大規模クエリによる複雑なデータ変換パイプラインを構築
  - クライアント要望への即日対応により、継続的なロジック改善を実現
  - 旅行経路分析の精度向上により、ビジネス判断の質を改善
- **技術**: BigQuery, Standard SQL, JavaScript UDF, Haversine距離計算, CTE, Window関数

### 3. 📚 学習管理システムとBigQueryを連携するETLパイプライン構築
**役割**: データエンジニア

- 企業向け学習管理システムの利用データを分析基盤に集約するため、日次でデータを自動取得・変換・格納するETLパイプラインをGCP上に構築
- **技術実装**: 
  - Cloud FunctionsでのPython ETLパイプライン開発（約6種類のデータ処理）
  - AES-256暗号化による個人情報保護（暗号化キーはSecret Managerで管理）
  - Cloud Loggingと連携した2段階アラートシステム（WARNING/ERRORレベル）
  - GET/POST両方に対応した汎用的な取得関数を実装し、テーブル固有の条件をパラメータ化
- **成果**: 
  - 日次バッチの安定稼働率99.9%を達成
  - エラー発生から対応までの時間を平均30分以内に短縮
  - 手動作業ゼロの完全自動化を実現
  - データ分析チームが即座に活用できる環境を実現
- **技術**: BigQuery, Cloud Functions, Python (cryptography, requests, google-cloud-bigquery, google-cloud-secret-manager, google-cloud-logging), AES-256暗号化, OAuth 2.0

### 4. 👗 アパレル4ブランド マーケティングタグ管理基盤の大規模統合移行プロジェクト
**役割**: データエンジニア（実装・検証担当）  
**期間**: 2024年3月〜2025年1月（約11ヶ月）  
**チーム規模**: 5名

- アパレル4ブランド（nojess、A_S、bellesiora、agete/ronherman）のタグ管理システム（Tealium、Braze、LINE STAFF START、Silver Egg、Repro等）をGoogle Tag Manager（GTM）に統合移行
- **プロジェクト規模**: 
  - 総作業項目数：2,400以上（変数：886個、トリガー：393個、カスタムHTMLタグ：646個、タグ構成：548個）
  - GA4 Eコマースイベント：11種類（view_item、add_to_cart、purchase等）
  - 総テスト項目数：2,724項目（変数テスト1,068項目、拡張機能テスト689項目、GA4タグテスト448項目、その他タグテスト519項目）
- **技術実装**: 
  - Tealium→GTMのマッピングシート作成（4ブランド中2.5ブランド分を担当）
  - カスタムHTML/JavaScriptタグ開発（646個のロジック移植）
  - GA4イベント設計・実装（11種類：view_item_list、view_item、sign_up、search、begin_checkout、add_payment_info、purchase、refund、remove_from_cart、add_to_cart、view_cart）
  - 複雑なJavaScriptロジックの移植（条件分岐、配列処理、データレイヤー操作）
  - 網羅的テスト実施：2,724項目
- **成果**: 
  - マーケティングチームのタグ管理業務の統合・効率化を実現
  - タグ発火率を95%から99.8%に改善（2,724項目の網羅的テストにより全タグの正常動作を確認）
  - 4ブランドの並行移行を完遂
  - マーケティングチームがデータ活用しやすい環境を整備
- **技術**: GTM, GA4, JavaScript, dataLayer, Tealium, Braze, LINE STAFF START, Silver Egg, Repro

### 5. 🏠 不動産投資会社向けBigQueryデータ分析基盤構築
**役割**: データエンジニア（設計・実装担当）  
**期間**: 2024年2月（短期集中開発）  
**チーム規模**: 2名

- 物件評価・税務計算の自動化システムをBigQueryで構築
- **課題**: 
  - Excel管理されていた物件情報（購入検討物件100件以上）の分析が属人化
  - 固定資産税・都市計画税の計算が手動で、ミスが頻発（10%のエラー率）
  - 経営層の投資判断に3日以上かかっていた
- **技術実装**: 
  - 90カラム以上の大規模テーブル設計（物件基本情報、税務情報、賃貸情報）
  - 700行超のSQLクエリ開発（5段階CTE）
  - 複雑な税務計算ロジックの実装（想定/実績の2パターン対応）
  - 文字化けデータ（Shift-JIS/UTF-8混在）、日付フォーマット不統一の完全クレンジング
- **成果**: 
  - 投資判断のスピードを3日から即日に短縮
  - 税務計算の正確性が100%に向上（手動計算時は10%のエラー率）
  - 月40時間かかっていた物件評価作業を即座に実行可能に
- **技術**: BigQuery, StandardSQL, Google Sheets API, CTE

### 6. 👟 スポーツアパレル企業 BIデータマート構築・大規模データ集計基盤開発
**役割**: リードデータエンジニア（実装・レビュー・技術指導担当）  
**期間**: 2024年6月〜7月  
**チーム規模**: 5名（エンジニア3名、アナリスト2名）

- 年月週日別・チャネル別・会員属性別の多次元集計データマートを設計・構築
- **課題**: 経営層が必要とする売上分析が、複数のデータソースを手動で結合して行われており、分析に2日以上かかっていた
- **技術実装**: 
  - 300行超の大規模SQLクエリ開発（12パターンのUNION ALLで多次元集計を実現）
  - 5段階CTEによる段階的データ加工とWindow関数（DENSE_RANK、ROW_NUMBER）による購買順序・顧客判定
  - 2018年以降の全取引データ（約500万レコード）を10分以内で集計
  - Digdagによるワークフロー制御・ジョブスケジューリング構築
- **チーム技術指導**: 
  - ジュニアエンジニアに対してDigdagワークフローの設計思想を指導
  - 定義書12件のレビューを実施（カラム定義の不整合を20箇所以上発見・修正）
- **成果**: 
  - 分析リードタイムを2日から30分に短縮（96%削減）
  - 経営層が迅速に意思決定できる環境を実現
  - チームメンバーのSQL開発スキルを向上させ、独力での保守を可能に
- **技術**: Treasure Data, Presto SQL, Tableau, CTEs, Window関数, Digdag

### 7. 🎮 大手玩具メーカー マーケティングデータ連携基盤の構築
**役割**: データエンジニア（実装・顧客対応担当）  
**期間**: 2024年4月〜8月  
**チーム規模**: 3名

- Salesforce Marketing Cloud（マーケティングオートメーション）から分析基盤（Treasure Data）へのSFTP経由自動データ連携パイプラインを構築
- **課題**: 月40時間の作業時間が手動データ連携に費やされていた
- **技術実装**: 
  - YAMLベースの設定ファイルとDigdagワークフローによる日次バッチ自動化（約10万レコード/日）
  - データ型不整合問題（Long型に空文字混入）を2段階処理で解決（L1層String型→L2層Long型変換）
  - ログ分析により2時間以内に問題特定し、3時間以内に本番環境修正完了
- **成果**: 
  - 月40時間の作業時間削減、手動作業ゼロの完全自動化を実現
  - データ品質問題を3時間以内に解決し、マーケティングチームのビジネス影響を最小化
  - 技術文書（テーブル定義書、ワークフロー仕様書、テスト項目書）を整備し、保守性を向上
- **技術**: Treasure Data, Digdag, SFTP, Presto SQL, YAML

## 💡 技術的な強み

### 1. 大規模データ処理
- 500万レコード/日の高速処理実装
- 複雑なSQL（300行超、700行超、12パターンのUNION ALL）の最適化
- メモリ効率を考慮したパフォーマンスチューニング
- 10万件単位のバッチ処理とメモリクリアによる効率的な大容量データ処理

### 2. データ品質管理
- データ型不整合問題の迅速な解決（L1/L2層での段階的変換）
- 文字化け・フォーマット不統一への対応
- 包括的なテスト戦略（単体・結合・回帰テスト）
- 2,724項目の網羅的テストによる品質保証

### 3. チーム支援・教育
- ジュニアエンジニアへの技術指導
- ドキュメント整備による属人化防止
- コードレビューによる品質向上
- AI開発支援ツール（Claude、Cursor、GitHub Copilot）を活用した開発効率化

### 4. マーケティングデータ基盤
- 大規模タグ管理基盤の統合移行（2,400項目、4ブランド並行）
- GA4イベントトラッキング設計・実装（11種類のEコマースイベント）
- 複雑なJavaScriptロジックの移植（条件分岐、配列処理、データレイヤー操作）

### 5. 地理空間データ分析
- JavaScript UDFによるHaversine公式を用いた球面距離計算
- 異常値検出・補正アルゴリズムの開発
- 時系列データ処理と日付間の連続性担保

## 📈 ビジネスインパクト

- **業務効率化**: 手動作業を月40時間削減、手動作業ゼロの完全自動化を実現
- **意思決定の高速化**: 分析時間を2日から30分に短縮（96%削減）、投資判断を3日から即日に短縮
- **品質向上**: エラー率を10%から0.2%以下に改善、タグ発火率を95%から99.8%に改善、税務計算の正確性を100%に向上
- **コスト削減**: 自動化による人的リソースの最適化
- **データ活用基盤の整備**: マーケティングチームがデータを活用しやすい環境を構築

## 🎯 得意とする課題解決

✅ レガシーシステムのモダナイゼーション  
✅ リアルタイムデータパイプライン構築  
✅ 複雑なビジネスロジックのSQL実装  
✅ マルチソースデータの統合と正規化  
✅ スケーラブルなデータアーキテクチャ設計  

## 📫 Contact

- 🌐 [ポートフォリオサイト](https://sato1046.github.io)
- 💼 副業・業務委託のご相談はお気軽にご連絡ください

## 🔄 継続的な学習

常に最新技術をキャッチアップし、以下の分野でスキルを拡張しています：
- クラウドネイティブアーキテクチャ
- リアルタイムストリーミング処理
- MLOps/データサイエンス基盤
- データガバナンス・セキュリティ

---

### 🌟 お仕事のご依頼について

データ基盤構築、ETL開発、BI環境整備などのプロジェクトでお困りの際は、ぜひご相談ください。  
短期集中型のプロジェクトから長期的な支援まで、柔軟に対応いたします。

**対応可能な業務:**
- データ基盤の設計・構築
- ETL/ELTパイプライン開発
- データマート・DWH構築
- データ品質改善
- 技術支援・コンサルティング

---

*"データを価値に変える" - 複雑なデータ課題を、実用的なソリューションで解決します。*
